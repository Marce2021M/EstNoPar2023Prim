---
title: "Laboratorio 2 Estadística No Paramétrica"
author: "Jorge de la Vega"
date: "27/ene/23"
output: 
  html_document:
    theme: cerulean
editor_options: 
  chunk_output_type: console
---

```{css, echo=FALSE}
p {
  font-size: 18px;
}
li {
  font-size: 18px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center",
                      comment = NULL, warning = FALSE, fig.height = 5)
options(width=180)
```

# Sesión de ejercicios, ejemplos y aplicaciones.

## Estimación de cuantiles

1. El *Educational Testing Service* (ETS) reporta que el percentil 75 para puntuaciones en el examen GRE cuantitativo es 693 en un cierto año. Una muestra aleatoria de 15 estudiantes graduados de primer año en Estadística reportan sus puntuaciones GRE's en el área cuantitativa como 690, 750, 680, 700, 660, 710, 720, 730, 650, 670, 740, 730, 660, 750 y 690. ¿Son estas puntuaciones consistentes con el valor del percentil 75 para ese año?

**Solución**

Queremos ver si la disribución de los datos tiene el percentil 75 como se indica. Aquí $p=0.75$ y $\xi_{0.75}= 693$. Suponemos que $\alpha=0.05$.

Primero metemos los datos y definimos los valores dados

```{r}
X <- c(690, 750, 680, 700, 660, 710, 720, 730, 650, 670, 740, 730, 660, 750, 690)
xi <- 693
alfa <- 0.05
p <- 0.75
(n <- length(X))
```


- **Utilizando intervalos de confianza**. 

De acuerdo a lo visto en clase, requerimos encontrar $m$ y $s$ tal que $P(m \leq K \leq s-1) = 1-\alpha$, donde $K \sim Bin(n,p)$. Entonces

```{r}
round(pbinom(0:15,n,p),6)
```

Entonces $m=7$ y $s-1=13$ o $s=14$ y los límites del intervalo son: 

```{r}
sort(X)[c(7,14)]
```

con probabilidad

```{r}
pbinom(14,n,p) - pbinom(7,n,p)
```


- **Utilizando pruebas de hipótesis**. La hipótesis nula es $H_0:\xi_{0.75}=693$ y se puede evaluar respecto a la alternativa $H_a:\xi_{0.75}\neq 693$. La estadística de prueba $K$ está dada por: 

```{r}
K <- sum(ifelse(X - xi > 0, 1, 0)) # sumamos los signos positivos
K
```

La región de rechazo para $H_0$ con la alternativa dada $H_a:\xi_{0.75} \neq 693$ es $R = \{K | K \leq n-s \mbox{ o } K \geq n-l+1\}$ donde $l$ debe satisfacer $F_{bin(n,p)}(l-1) \leq \alpha/2$ y $s$ debe satisfacer $F_{bin(n,1-p)}(n-s) \leq \alpha/2$

Evaluando las probabilidades para encontrar $l$ y $s$

```{r}
round(pbinom(0:15, size = n, prob = p), 6)
round(pbinom(0:15, size = n, prob = 1-p),6)
```


```{r}
sum(pbinom(0:15, size = n, prob = p) < alfa/2) - 1 # l-1; el menos 1 es porque el indice empieza en 0
(l <- sum(pbinom(0:15, size = n, prob = p) < alfa/2)) # valor de l
sum(pbinom(0:15, size = n, prob = 1-p) < alfa/2) -1  # valor de n-s. menos 1 es porque el índice empieza en 0
(s <- n - 1 - sum(pbinom(0:15, size = n, prob = 1-p) < alfa/2)) # valor de s 
```

Entonces la región de rechazo es $K \leq 0$ o $K \geq 13$ con nivel de significancia exacto dado por $0.0134+0.0173=0.0307$

---

## Introducción al bootstrap

Muchas estadìsticas que se usan como estimadores de parámetros de poblaciones son difìciles o imposibles de obtener de manera teórica, así que se han desarrollado métodos de remuestreo que pemiten estimar sus medias y sus varianzas, como el *bootstrap*.

El método bootstrap muestrea $n$ valores **con reemplazo** de la muestra de datos originales de tamaño $n$. A cada una de estas muestras se le llama muestra bootstrap. 

El estimador de la cantidad de interés $\hat{\theta}$ se calcula para cada muestra bootstrap. La media y la desviación estándar de las muestras bootstrap se usa como estimadores de la media y desviación estándar de la distribución del estimador $\hat{\theta}$. 

Hay muchos métodos de calcular intervalos de confianza con bootstrap; uno es obtener los cuantiles $\alpha/2$ y $1-\alpha/2$ de la distribución bootstrap obtenida con al menos 250 répicas bootstrap.

2. La *Sociedad Hipotecaria Federal* (SHF) publica un índice de precios de la vivienda por estado y a nivel nacional. 

```{r}
datos <- read.csv("https://github.com/jvega68/EA3/raw/master/datos/SHF-IndicePreciosVivienda.csv", header=T)
```
Queremos estimar la correlación que hay entre los datos del 2o trimestre de 2022 y los del 3er trimestre de 2020, junto con un intervalo de confianza del 95% usando bootstrap.

**Solución**

```{r}
X <- datos[,c(6,13)] #Selecciona las columnas que interesan
rhohat <- cor(X$X3T20,X$X2T22)  # Estimado de la muestra
B <- 1000 # Número de réplicas bootstrap
rhoboot <- NULL 
set.seed <- 100 # Siempre que se generen números aleatorios, conviene fijar la semillac
for(i in 1:B){
  ind <- sample(1:nrow(X),size = nrow(X), replace=T)
  rhoboot[i] <- cor(X$X3T20[ind],X$X2T22[ind])
}
hist(rhoboot,breaks = 100)
sd(rhoboot) # Estimado de la desviación estándar del estimador. 
quantile(rhoboot,probs = c(0.025,0.975))
```

## Nota sobre corrección de continuidad

3. Si $Y\sim Bin(n,p)$, tenemos que $P(Y\leq k) = P(Y\leq k + \epsilon)$ para $\epsilon\in [0,1)$ porque solo toma valores enteros. Entonces ¿qué valor debería usarse cuando se aproxima la cantidad con una distribución normal? La corrección por continuidad propone tomar el punto medio entre dos valores consecutivos ($k+0.5$) como aproximación a los valores:

\[ P(Y\leq k) \approx P\left(Z\leq \frac{k+0.5-np}{\sqrt{np(1-p)}} \right) \]

Tomando $n=20$, $p=0.1$, $\alpha= 0.05$ calcular con y sin corrección para ver cuál está más cerca. Repetir con $p=0.3$.

** Solución** 
```{r}
n <- 20
p <- 0.1
round(pbinom(1,n,p),5) # valor exacto
round(pnorm((1-p*n)/sqrt(n*p*(1-p))),5)  # aproximación normal sin corrección
round(pnorm((1+0.5-p*n)/sqrt(n*p*(1-p))),5)  # aproximación normal con corrección
```


## Prueba del signo

4. Seis estudiantes entraron a dieta en un intento de bajar de peso, con los siguientes resultados (en libras)

```{r}
peso <- data.frame(Nombre = c("Abdul", "Ed", "Jim", "Max", "Phil", "Ray"),
                   antes = c(174, 191, 188, 182, 201, 188),
                   despues = c(165, 186, 183, 178, 203, 181))
```

¿Es la dieta efectiva en términos de perder peso?

**Solución**

La prueba es efectiva si las personas pierden peso. Entonces la prueba a realizar es $H_0: P(+) = P(-)$ vs $H_a:P(+) > P(-)$, donde el signo más es que la persona perdió peso.

```{r}
res <- ifelse(peso$despues-peso$antes<0,1,0)
K <- sum(res)
pnorm(K,nrow(peso),0.5) # p-value. Valores grandes de K quiere decir que el + es más probable.
```

Por lo tanto la conclusión es que hay evidencia estadística para decir que la dieta es efectiva.
