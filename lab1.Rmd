---
title: "Estadística no paramétrica - Lab 1"
author: "Jorge de la Vega"
date: "12 de enero de 2023"
output: 
  html_document:
    theme: cerulean
editor_options: 
  chunk_output_type: console
---

```{css, echo=FALSE}
p {
  font-size: 18px;
}
li {
  font-size: 18px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center",
                      comment = NULL, warning = FALSE, fig.height = 5)
options(width=180)
```

# Estimación de funciones de distribución empíricas. 

## Ejercicio 1. 

Supongan que les dan las siguientes 100 observaciones. Encontrar la función de distribución estimada máximo verosímil y una banda de confianza del 95% para el estimador de la función de distribución. ¿Se puede decir algo sobre si los datos provienen de una $N(0,1)$?

```{r}
datos <- c(-0.16,-0.68,-0.32,-0.85, 0.89,-2.28, 0.63, 0.41, 0.15, 0.74, 1.30,-0.13, 0.80,
           -0.75, 0.28,-1.00, 0.14,-1.38,-0.04,-0.25,-0.17, 1.29, 0.47,-1.23, 0.21,-0.04,
            0.07,-0.08, 0.32,-0.17, 0.13,-1.94, 0.78, 0.19,-0.12,-0.19, 0.76,-1.48,-0.01,
            0.20,-1.97,-0.37, 3.08,-0.40, 0.80, 0.01, 1.32,-0.47, 2.29,-0.26,-1.52,-0.06,
           -1.02, 1.06, 0.60, 1.15, 1.92,-0.06,-0.19, 0.67, 0.29, 0.58, 0.02, 2.18,-0.04,
           -0.13,-0.79,-1.28,-1.41,-0.23, 0.65,-0.26,-0.17,-1.53,-1.69,-1.60, 0.09,-1.11, 
            0.30, 0.71,-0.88,-0.03, 0.56,-3.68, 2.40, 0.62, 0.52,-1.25, 0.85,-0.09,-0.23,
           -1.16, 0.22,-1.68, 0.50,-0.35,-0.35,-0.33,-0.24, 0.25)
```

**Solución**

Podemos simplificar un poco la notación abajo si primero ordenamos los datos (generando entonces las estadísticas de orden de la muestra)

```{r}
datos_ord <- sort(datos)  #ordena los datos por default en orden creciente.
```

De acuerdo a lo visto en clase, el estimador máximo-verosímil de la función de distribución $F$ de los datos es la función de distribución empírica $\hat{F}_n$, que se puede obtener con la función `ecdf`.

```{r}
dis <- ecdf(datos_ord)
plot(datos_ord, dis(datos_ord), type = "S", 
    main = "Función de distribución empírica", 
    xlab = "x", ylab = expression(hat(F)[n])) # noten que dist es una función!
```

La banda de confianza la podemos encontrar con la fórmula vista en la primera clase

```{r}
n <- length(datos) # número de observaciones.
alfa <- 0.05
(eps <- sqrt(log(2/alfa)/(2*n))) #los paréntesis se agregan para que el resultado de la asignación se imprima

plot(datos_ord, dis(datos_ord), type = "S", main ="Banda de confianza de la distribución empírica", 
     xlab="x", ylab=expression(hat(F)[n](x)))
abline(h = 1, lty = 2, col = "gray", lwd = 2)
rug(datos_ord, ticksize = 0.02, col = "blue") #agrega la ubicación de los puntos.
lines(datos_ord, pmax(dis(datos_ord) - eps, 0), col = "red", type = "S") #banda superior
lines(datos_ord, pmin(dis(datos_ord) + eps, 1), col = "red", type = "S") #banda inferior
```

La última pregunta nos pide probar la hipótesis $H_0: F \equiv N(0,1)$ vs $ H_a: F \neq N(0,1)$. Aquí se puede utilizar la prueba de Kolmogorov-Smirnov de bondad de ajuste

```{r}
ks.test(datos_ord, pnorm, alternative = "two.sided")
```

El *warning* nos lo da porque los datos tienen una observación repetida, lo cual tiene probabilidad 0 bajo una distribución continua, y en los datos hay varias repeticiones de datos, por ejemplo, -0.04 aparece 3 veces. Ignorando el aviso, vemos que el p-value es 0.3191, por lo que no tenemos evidencia para rechazar la hipótesis. Podemos agregar a la gráfica la curva normal para ver si cae en el intervalo de confianza:

```{r}
plot(datos_ord, dis(datos_ord), type = "S", main="Comparación entre distribuciones", xlab="x", ylab="")
abline(h = 1, lty = 2, col = "gray", lwd = 2)
rug(datos_ord, ticksize=0.02, col = "blue")
lines(datos_ord,pmax(dis(datos_ord) - eps, 0), col = "red", type = "S")
lines(datos_ord,pmin(dis(datos_ord) + eps, 1), col = "red", type = "S")
lines(datos_ord,pnorm(datos_ord),col="green3", lwd =2)
```

Vemos que la curva normal cae dentro de la banda de confianza del 95% uniformemente.

---

## Ejercicio 2

Cada persona en una muestra aleatoria de $n=10$ empleados les preguntaron acerca del tiempo diario $X$ gastado en actividades no relacionadas con el trabajo, tal como navegar por internet, y mandando emails a amigos. Los datos resultantes, en minutos son los siguientes. 

```{r}
X <- c(108, 112, 117, 130, 111, 131, 113, 113, 105, 128)
```

Usar los datos para encontrar una banda de confianza del 99% para la distribución de probabilidad desconocida $F(x)$.

**Solución**

Ejercicio similar al previo. Sólo hay que actualizar el nivel de significancia. Como el procedimiento es similar, podemos aprovechar la ocasión para definir una función que haga el cálculo por nosotros

```{r}
banda.distr <- function(x, alfa=0.05){
    # función que calcula banda de confianza de nivel 1-alfa
    # alrededor de la distribución empírica de una muestra x al 
    n <- length(x) # número de observaciones.
    x_ord <- sort(x) # ordena los dato
    dis <- ecdf(x_ord) #función de distribución empírica
    eps <- sqrt(log(2/alfa)/(2*n))
    plot(x_ord, dis(x_ord), ylim = c(0,1), type = "S", xlab = "x", ylab = expression(hat(F)[n](x)),
         main = paste("Banda de confianza de ",100*(1-alfa),"% para dist empírica",sep=""))
    abline(h = 1, lty = 2, col = "gray", lwd = 2)
    rug(x_ord, ticksize = 0.03, col = "blue")
    lines(x_ord,pmax(dis(x_ord) - eps, 0), col = "red", type = "S")
    lines(x_ord,pmin(dis(x_ord) + eps, 1), col = "red", type = "S")
}

```
Entonces para nuestro ejercicio:

```{r}
banda.distr(X,alfa=0.01)
```

En este caso hay muy pocos datos, de ahí la apariencia de la curva y del intervalo de confianza.

---

# Ejemplo de cobertura de intervalos

Para evaluar el desempeño de varios conjuntos de confianza que se pueden calcular en diversos contextos de estimación, se debe evaluar la **probabilidad de cobertura**: $P(p \in C)$ donde $C$ es el conjunto de confianza y $p$ es la cantidad de interés.

No es un problema fácil de resolver analíticamente, hay que hacerlo por simulación. 

## Ejercicio 3. 

Ejemplo de cobertura de intervalo de probabilidad binomial. Hacemos la gráfica de cobertura para distintos valores de $p$


```{r}
n <- 30   # Tamaño de muestra
X <- 0:n  # Posibles valores del número de éxitos en n ensayos
p <- 0.80
phat <- X/n  # estimador de la probabilidad
li <- phat - 1.96*sqrt(phat*(1-phat)/n)
ls <- phat + 1.96*sqrt(phat*(1-phat)/n)

# Suponiendo el verdadero valor del parámetro
prob <- dbinom(X, n, p)  # probabilidades
cobertura <-  (p > li ) & (p < ls)  # determina si estas en el intervalo o no
round(cbind(X, phat, li, ls, prob, cobertura),4)

# Probabilidad de cobertura en p
sum(dbinom(X[cobertura],n,p))
```

Càlculo de la probabilidad de cobertura para un caso en particular: 

```{r}
k <- 1000 # número de muestras montecarlo para el cálculo del coverage
p <- 0.8
n <- 30
alpha <- 0.05
# Diferentes intervalos
Wald <- vector(length = k)
for(i in 1:k){
  x <- rbinom(n,1,p) # Muestra aleatoria
  xbar <- mean(x)
  sd <- sqrt(xbar*(1-xbar)/n)
  ci <- xbar + c(-1,1)*qnorm(1-alpha/2,lower.tail = T)*sd
  Wald[i] <- ifelse((p <= ci[2]) & (p >= ci[1]), 1, 0)
  # Intervalo exacto
  
}
sum(Wald)/k
```

Extendiendo para varios posibles valores de $p$

```{r}
n <- 100                # tamaño de muestra
alfa <- 0.05           # nivel significancia
k <- qnorm(1-alfa/2)   # cuantil
aj <- 0               # ajuste por continuidad

X <- 0:n
phat <- (X+aj)/(n+2*aj)
margen.error <- k*sqrt(phat*(1 - phat)/(n + 2*aj))
li <- phat - margen.error
ls <- phat + margen.error
# exacto

m <- 2000
p <- seq(1/n, 1-1/n, length = m)
p.cob <- numeric(m)

for(i in 1:m){
  cober <- (p[i] >= li) & (p[i] <= ls)
  probs <- dbinom(X[cober], n, p[i])
  p.cob[i] <- sum(probs)
}
plot(p, p.cob, type = "l", main = paste("Cobertura real cuando n = ",n))
abline(h = 0.95)
```

Comparando la cobertura de diferentes métodos de estimación de la banda de confianza: 

```{r}
library(Hmisc)  # para usar la función binconf que calcula los intervalos 

binconf.varstab <- function (x, n, alfa){
# Función que calcula los intervalos de confianza basados en transoformación para estabilizar varianza
  len <- length(x)
  ci.matrix <- matrix(0, len, 2) # matriz de len renglones y dos columnas para guardar los cálculos
    for(r in 1:len){   
        phat <- x[r]/n
        h1 <- asin(sqrt(phat))
        h2 <- 0.5*qnorm(alfa/2, lower.tail = F)/sqrt(n)
        ci.matrix[r,] <- c((sin(h1-h2))^2, (sin(h1+h2))^2)
    }
    return(ci.matrix)
}

m <- 100                        # número de simlaciones
n <- 20
p <- seq(1/n, 1-1/n, length = m)  # vector de probabilidades verdaderas
Res <- matrix(0, length(p), 4)    # matriz de resultados

for (j in 1:length(p)){
    p0 <- p[j]
    x  <- rbinom(m, n, prob = p0)

    res.exact <- binconf(x, n, method = "exact", alpha = alfa, include.x = TRUE, include.n = TRUE)
    res.asymp <- binconf(x, n, method = "asymptotic", alpha = alfa, include.x=TRUE, include.n = TRUE)
    res.wilson <- binconf(x, n, method = "wilson", alpha = alfa, include.x = TRUE, include.n = TRUE)
    res.varstab <- binconf.varstab(x, n, alfa)
    # calcula las proporciones de cubierta
    exact <- sum((p0 >= res.exact[,4]) & (p0 <= res.exact[,5]))/m
    asymp <- sum((p0 >= res.asymp[,4]) & (p0 <= res.asymp[, 5]))/m
    wil   <- sum((p0 >= res.wilson[,4]) & (p0 <= res.wilson[, 5]))/m
    varstab<-sum((p0 >= res.varstab[,1]) & (p0 <= res.varstab[,2]))/m
    Res[j,] <- c(exact, asymp, wil, varstab)
}

# Grafica
plot(p, Res[,1], type = "l", col = "black", 
             xlab = 'Prob real de éxito', 
             ylab = 'proporción Cobertura ',ylim=c(0.5,1))

lines(p, Res[,2], col = "blue")
lines(p, Res[,3], col = "red")
lines(p, Res[,4], col = "green")
title(paste('Proporción de cobertura de IC binomial, n = ',as.character(n)))

legend("bottomright", c("Exacta", "Asintótica", "Wilson"," Varstab"), 
       col = c("black", "blue", "red", "green"),
       merge = TRUE, lty = rep(1,5))
abline(h = 1-alfa)
```


